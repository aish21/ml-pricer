{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f79724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (3.11.3)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras) (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras) (2.3.2)\n",
      "Requirement already satisfied: rich in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras) (3.14.0)\n",
      "Requirement already satisfied: optree in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras) (0.17.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras) (0.5.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras) (25.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorflow) (6.32.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: pillow in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from rich->keras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from rich->keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: keras_tuner in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (1.4.7)\n",
      "Requirement already satisfied: keras in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras_tuner) (3.11.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras_tuner) (25.0)\n",
      "Requirement already satisfied: requests in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras_tuner) (2.32.5)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras_tuner) (1.0.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras->keras_tuner) (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras->keras_tuner) (2.3.2)\n",
      "Requirement already satisfied: rich in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras->keras_tuner) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras->keras_tuner) (0.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras->keras_tuner) (3.14.0)\n",
      "Requirement already satisfied: optree in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras->keras_tuner) (0.17.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from keras->keras_tuner) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from requests->keras_tuner) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from requests->keras_tuner) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from requests->keras_tuner) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from requests->keras_tuner) (2025.8.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from optree->keras->keras_tuner) (4.15.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from rich->keras->keras_tuner) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from rich->keras->keras_tuner) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\aisha\\onedrive\\desktop\\github\\neural-pricer\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install keras tensorflow --upgrade\n",
    "!{sys.executable} -m pip install keras_tuner\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f994c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/raw/training_data.npz\"\n",
    "SCALER_DIR = \"../data/processed/scalers\"\n",
    "MODEL_DIR = \"../src/models\"\n",
    "FIGURE_DIR = \"../src/visualization/plots\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(FIGURE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17623456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: X shape (450000, 15), y shape (450000,)\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(path=DATA_PATH):\n",
    "    \"\"\"Load dataset from NPZ file.\"\"\"\n",
    "    data = np.load(path)\n",
    "    X, y = data[\"X\"], data[\"y\"]\n",
    "    print(f\"Loaded dataset: X shape {X.shape}, y shape {y.shape}\")\n",
    "    return X, y\n",
    "\n",
    "X, y = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9110167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (360000, 15), Test set: (90000, 15)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits into train/test and normalizes features.\n",
    "    Prefix prices + numeric features are scaled.\n",
    "    opt_flag is kept as-is (categorical 0/1).\n",
    "    \"\"\"\n",
    "    # Split train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Separate opt_flag (last column)\n",
    "    X_train_prefix = X_train[:, :-1]\n",
    "    X_test_prefix = X_test[:, :-1]\n",
    "\n",
    "    opt_flag_train = X_train[:, -1].reshape(-1, 1)\n",
    "    opt_flag_test = X_test[:, -1].reshape(-1, 1)\n",
    "\n",
    "    # Scale everything except opt_flag\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_prefix)\n",
    "    X_test_scaled = scaler.transform(X_test_prefix)\n",
    "\n",
    "    # Reattach opt_flag\n",
    "    X_train_final = np.hstack([X_train_scaled, opt_flag_train])\n",
    "    X_test_final = np.hstack([X_test_scaled, opt_flag_test])\n",
    "\n",
    "    # Save scaler for later inference\n",
    "    os.makedirs(SCALER_DIR, exist_ok=True)\n",
    "    joblib.dump(scaler, os.path.join(SCALER_DIR, \"feature_scaler.pkl\"))\n",
    "\n",
    "    print(f\"Train set: {X_train_final.shape}, Test set: {X_test_final.shape}\")\n",
    "    return X_train_final, X_test_final, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cef6be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f90b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(history, title, filename):\n",
    "    \"\"\"Save training curves for loss + MAE + RMSE.\"\"\"\n",
    "    plt.figure(figsize=(15, 4))\n",
    "\n",
    "    # Loss plot\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "    plt.title(f\"{title} - Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # MAE plot\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history.history[\"mae\"], label=\"Train MAE\")\n",
    "    plt.plot(history.history[\"val_mae\"], label=\"Val MAE\")\n",
    "    plt.title(f\"{title} - MAE\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mean Absolute Error\")\n",
    "    plt.legend()\n",
    "\n",
    "    # RMSE plot (computed from loss)\n",
    "    train_rmse = np.sqrt(history.history[\"loss\"])\n",
    "    val_rmse = np.sqrt(history.history[\"val_loss\"])\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(train_rmse, label=\"Train RMSE\")\n",
    "    plt.plot(val_rmse, label=\"Val RMSE\")\n",
    "    plt.title(f\"{title} - RMSE\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Root MSE\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURE_DIR, filename))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0165c5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 765us/step - loss: 95.7995 - mae: 6.1141 - val_loss: 91.7610 - val_mae: 5.8399\n",
      "Epoch 2/10\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 743us/step - loss: 91.3910 - mae: 5.8572 - val_loss: 91.8453 - val_mae: 5.8321\n",
      "Epoch 3/10\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 745us/step - loss: 91.1803 - mae: 5.8401 - val_loss: 92.0253 - val_mae: 5.7847\n",
      "Epoch 4/10\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 744us/step - loss: 91.0460 - mae: 5.8312 - val_loss: 91.6385 - val_mae: 5.8261\n",
      "Epoch 5/10\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 745us/step - loss: 91.0170 - mae: 5.8271 - val_loss: 91.2610 - val_mae: 5.8690\n",
      "Epoch 6/10\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 776us/step - loss: 90.9624 - mae: 5.8224 - val_loss: 91.3123 - val_mae: 5.8537\n",
      "Epoch 7/10\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 763us/step - loss: 90.9252 - mae: 5.8189 - val_loss: 91.8168 - val_mae: 5.8414\n",
      "Epoch 8/10\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 800us/step - loss: 90.8532 - mae: 5.8174 - val_loss: 91.9342 - val_mae: 5.7876\n",
      "Epoch 9/10\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 750us/step - loss: 90.7997 - mae: 5.8135 - val_loss: 91.3356 - val_mae: 5.8872\n",
      "Epoch 10/10\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 749us/step - loss: 90.7435 - mae: 5.8123 - val_loss: 91.3940 - val_mae: 5.8552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 392us/step\n",
      "Evaluation on Test Set -> MAE: 5.8552, RMSE: 9.5600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(5.855225371268371), np.float64(9.56002060306431))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_quick_mlp(input_dim):\n",
    "    \"\"\"Small, quick baseline MLP.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"linear\")\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Compute MAE and RMSE on test set.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = np.mean(np.abs(y_test - y_pred.flatten()))\n",
    "    rmse = np.sqrt(np.mean((y_test - y_pred.flatten()) ** 2))\n",
    "    print(f\"Evaluation on Test Set -> MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
    "    return mae, rmse\n",
    "\n",
    "quick_mlp = build_quick_mlp(input_dim)\n",
    "history_quick = quick_mlp.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n",
    "quick_mlp.save(os.path.join(MODEL_DIR, \"mlp_quick.h5\"))\n",
    "plot_training(history_quick, \"Quick MLP\", \"training_quick_run_2.png\")\n",
    "evaluate_model(quick_mlp, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc39133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_large_mlp(hp):\n",
    "    model = keras.Sequential()\n",
    "    input_dim = X_train.shape[1]\n",
    "\n",
    "    # Input layer\n",
    "    model.add(layers.Input(shape=(input_dim,)))\n",
    "\n",
    "    # Number of hidden layers\n",
    "    num_layers = hp.Int(\"num_layers\", min_value=2, max_value=6, step=1)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        units = hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32)\n",
    "        activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "        model.add(layers.Dense(units=units, activation=activation))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer_choice = hp.Choice(\"optimizer\", [\"adam\", \"sgd\"])\n",
    "    learning_rate = hp.Float(\"lr\", 1e-4, 1e-2, sampling=\"log\")\n",
    "\n",
    "    if optimizer_choice == \"adam\":\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\", \"mse\", \"accuracy\"]  # include accuracy for monitoring\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed55014b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from tuner_logs\\large_mlp_tuning\\tuner0.json\n",
      "  - num_layers: 3\n",
      "  - units_0: 96\n",
      "  - activation: relu\n",
      "  - units_1: 192\n",
      "  - optimizer: sgd\n",
      "  - lr: 0.0005822751269209618\n",
      "  - units_2: 352\n",
      "  - units_3: 320\n",
      "  - units_4: 384\n",
      "  - units_5: 352\n",
      "  - tuner/epochs: 6\n",
      "  - tuner/initial_epoch: 0\n",
      "  - tuner/bracket: 2\n",
      "  - tuner/round: 0\n"
     ]
    }
   ],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_large_mlp,\n",
    "    objective=\"val_mae\",\n",
    "    max_epochs=50,  # upper bound for epochs\n",
    "    factor=3,\n",
    "    directory=\"tuner_logs\",\n",
    "    project_name=\"large_mlp_tuning\"\n",
    ")\n",
    "\n",
    "stop_early = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[stop_early],\n",
    "    batch_size=kt.HyperParameters().Int(\"batch_size\", min_value=32, max_value=256, step=32),\n",
    "    epochs=50\n",
    ")\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "for hp in best_hps.values.keys():\n",
    "    print(f\"  - {hp}: {best_hps.get(hp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20f0db27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1506 - loss: 95.1052 - mae: 5.9999 - mse: 95.1052 - val_accuracy: 0.1557 - val_loss: 93.3885 - val_mae: 6.0633 - val_mse: 93.3885\n",
      "Epoch 2/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 999us/step - accuracy: 0.1744 - loss: 91.7001 - mae: 5.8265 - mse: 91.7001 - val_accuracy: 0.1596 - val_loss: 91.6718 - val_mae: 5.9242 - val_mse: 91.6718\n",
      "Epoch 3/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1756 - loss: 91.4042 - mae: 5.8137 - mse: 91.4042 - val_accuracy: 0.1588 - val_loss: 91.5821 - val_mae: 5.8260 - val_mse: 91.5821\n",
      "Epoch 4/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1740 - loss: 91.2848 - mae: 5.8116 - mse: 91.2848 - val_accuracy: 0.1635 - val_loss: 91.4617 - val_mae: 5.8691 - val_mse: 91.4617\n",
      "Epoch 5/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1743 - loss: 91.1743 - mae: 5.8087 - mse: 91.1743 - val_accuracy: 0.1635 - val_loss: 91.2359 - val_mae: 5.8649 - val_mse: 91.2359\n",
      "Epoch 6/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1720 - loss: 91.1180 - mae: 5.8087 - mse: 91.1180 - val_accuracy: 0.1626 - val_loss: 91.2213 - val_mae: 5.8942 - val_mse: 91.2213\n",
      "Epoch 7/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1722 - loss: 91.0452 - mae: 5.8060 - mse: 91.0452 - val_accuracy: 0.1533 - val_loss: 91.9283 - val_mae: 5.9837 - val_mse: 91.9283\n",
      "Epoch 8/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1725 - loss: 91.0007 - mae: 5.8065 - mse: 91.0007 - val_accuracy: 0.1822 - val_loss: 91.4853 - val_mae: 5.8024 - val_mse: 91.4853\n",
      "Epoch 9/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1720 - loss: 90.9511 - mae: 5.8073 - mse: 90.9511 - val_accuracy: 0.1774 - val_loss: 91.9571 - val_mae: 5.8628 - val_mse: 91.9571\n",
      "Epoch 10/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1710 - loss: 90.9096 - mae: 5.8055 - mse: 90.9096 - val_accuracy: 0.1578 - val_loss: 91.3682 - val_mae: 5.8225 - val_mse: 91.3682\n",
      "Epoch 11/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1709 - loss: 90.8717 - mae: 5.8038 - mse: 90.8717 - val_accuracy: 0.1642 - val_loss: 91.7878 - val_mae: 5.8579 - val_mse: 91.7878\n",
      "Epoch 12/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1689 - loss: 90.8732 - mae: 5.8035 - mse: 90.8732 - val_accuracy: 0.1496 - val_loss: 91.3656 - val_mae: 5.8984 - val_mse: 91.3656\n",
      "Epoch 13/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1690 - loss: 90.8689 - mae: 5.8070 - mse: 90.8689 - val_accuracy: 0.1901 - val_loss: 91.4410 - val_mae: 5.8245 - val_mse: 91.4410\n",
      "Epoch 14/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1701 - loss: 90.7894 - mae: 5.8022 - mse: 90.7894 - val_accuracy: 0.1541 - val_loss: 91.4775 - val_mae: 5.9060 - val_mse: 91.4775\n",
      "Epoch 15/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1708 - loss: 90.7683 - mae: 5.8019 - mse: 90.7683 - val_accuracy: 0.1678 - val_loss: 91.4491 - val_mae: 5.8657 - val_mse: 91.4491\n",
      "Epoch 16/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1699 - loss: 90.7700 - mae: 5.8032 - mse: 90.7700 - val_accuracy: 0.1610 - val_loss: 91.5037 - val_mae: 5.8615 - val_mse: 91.5037\n",
      "Epoch 17/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1690 - loss: 90.7453 - mae: 5.8015 - mse: 90.7453 - val_accuracy: 0.1527 - val_loss: 91.1626 - val_mae: 5.8582 - val_mse: 91.1626\n",
      "Epoch 18/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1694 - loss: 90.7516 - mae: 5.8013 - mse: 90.7516 - val_accuracy: 0.1641 - val_loss: 91.8298 - val_mae: 5.8723 - val_mse: 91.8298\n",
      "Epoch 19/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1698 - loss: 90.6870 - mae: 5.8024 - mse: 90.6870 - val_accuracy: 0.1880 - val_loss: 91.2816 - val_mae: 5.8182 - val_mse: 91.2816\n",
      "Epoch 20/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1693 - loss: 90.6631 - mae: 5.8004 - mse: 90.6631 - val_accuracy: 0.1568 - val_loss: 91.5077 - val_mae: 5.8610 - val_mse: 91.5077\n",
      "Epoch 21/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1692 - loss: 90.6354 - mae: 5.7998 - mse: 90.6354 - val_accuracy: 0.1744 - val_loss: 92.9059 - val_mae: 5.8037 - val_mse: 92.9059\n",
      "Epoch 22/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1690 - loss: 90.6278 - mae: 5.8019 - mse: 90.6278 - val_accuracy: 0.1797 - val_loss: 91.6310 - val_mae: 5.8758 - val_mse: 91.6310\n",
      "Epoch 23/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1701 - loss: 90.6035 - mae: 5.7999 - mse: 90.6035 - val_accuracy: 0.1726 - val_loss: 91.5470 - val_mae: 5.8454 - val_mse: 91.5470\n",
      "Epoch 24/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1700 - loss: 90.5810 - mae: 5.7989 - mse: 90.5810 - val_accuracy: 0.1918 - val_loss: 91.3803 - val_mae: 5.7701 - val_mse: 91.3803\n",
      "Epoch 25/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1687 - loss: 90.5824 - mae: 5.7989 - mse: 90.5824 - val_accuracy: 0.1578 - val_loss: 92.5841 - val_mae: 5.8784 - val_mse: 92.5841\n",
      "Epoch 26/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1707 - loss: 90.4986 - mae: 5.7985 - mse: 90.4986 - val_accuracy: 0.1652 - val_loss: 91.4163 - val_mae: 5.8221 - val_mse: 91.4163\n",
      "Epoch 27/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1692 - loss: 90.5116 - mae: 5.7978 - mse: 90.5116 - val_accuracy: 0.1688 - val_loss: 91.3283 - val_mae: 5.8437 - val_mse: 91.3283\n",
      "Epoch 28/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1698 - loss: 90.4918 - mae: 5.7967 - mse: 90.4918 - val_accuracy: 0.1792 - val_loss: 91.6838 - val_mae: 5.7805 - val_mse: 91.6838\n",
      "Epoch 29/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1705 - loss: 90.4916 - mae: 5.7956 - mse: 90.4916 - val_accuracy: 0.1904 - val_loss: 91.1689 - val_mae: 5.7800 - val_mse: 91.1689\n",
      "Epoch 30/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1705 - loss: 90.4425 - mae: 5.7958 - mse: 90.4425 - val_accuracy: 0.1484 - val_loss: 91.2599 - val_mae: 5.8721 - val_mse: 91.2599\n",
      "Epoch 31/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1698 - loss: 90.4166 - mae: 5.7970 - mse: 90.4166 - val_accuracy: 0.1685 - val_loss: 92.5852 - val_mae: 5.8114 - val_mse: 92.5852\n",
      "Epoch 32/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1701 - loss: 90.4036 - mae: 5.7959 - mse: 90.4036 - val_accuracy: 0.1759 - val_loss: 91.5479 - val_mae: 5.8686 - val_mse: 91.5479\n",
      "Epoch 33/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1714 - loss: 90.3238 - mae: 5.7934 - mse: 90.3238 - val_accuracy: 0.1615 - val_loss: 91.5023 - val_mae: 5.8714 - val_mse: 91.5023\n",
      "Epoch 34/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1701 - loss: 90.3474 - mae: 5.7938 - mse: 90.3474 - val_accuracy: 0.1936 - val_loss: 91.4218 - val_mae: 5.8350 - val_mse: 91.4218\n",
      "Epoch 35/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1710 - loss: 90.3118 - mae: 5.7917 - mse: 90.3118 - val_accuracy: 0.1691 - val_loss: 92.2135 - val_mae: 5.8417 - val_mse: 92.2135\n",
      "Epoch 36/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1704 - loss: 90.3091 - mae: 5.7946 - mse: 90.3091 - val_accuracy: 0.1724 - val_loss: 92.2297 - val_mae: 5.8799 - val_mse: 92.2297\n",
      "Epoch 37/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1707 - loss: 90.2549 - mae: 5.7896 - mse: 90.2549 - val_accuracy: 0.1753 - val_loss: 91.4770 - val_mae: 5.8676 - val_mse: 91.4770\n",
      "Epoch 38/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1712 - loss: 90.2334 - mae: 5.7903 - mse: 90.2334 - val_accuracy: 0.1720 - val_loss: 92.6545 - val_mae: 5.8815 - val_mse: 92.6545\n",
      "Epoch 39/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1709 - loss: 90.1844 - mae: 5.7885 - mse: 90.1844 - val_accuracy: 0.1336 - val_loss: 92.1563 - val_mae: 6.0084 - val_mse: 92.1563\n",
      "Epoch 40/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1709 - loss: 90.1877 - mae: 5.7909 - mse: 90.1877 - val_accuracy: 0.1764 - val_loss: 91.6355 - val_mae: 5.8667 - val_mse: 91.6355\n",
      "Epoch 41/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1711 - loss: 90.1065 - mae: 5.7895 - mse: 90.1065 - val_accuracy: 0.1759 - val_loss: 91.7723 - val_mae: 5.9207 - val_mse: 91.7723\n",
      "Epoch 42/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1703 - loss: 90.1063 - mae: 5.7894 - mse: 90.1063 - val_accuracy: 0.1595 - val_loss: 91.7781 - val_mae: 5.9051 - val_mse: 91.7781\n",
      "Epoch 43/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1709 - loss: 90.0744 - mae: 5.7856 - mse: 90.0744 - val_accuracy: 0.1702 - val_loss: 91.5783 - val_mae: 5.8763 - val_mse: 91.5783\n",
      "Epoch 44/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1720 - loss: 90.0015 - mae: 5.7880 - mse: 90.0015 - val_accuracy: 0.1668 - val_loss: 91.9965 - val_mae: 5.8249 - val_mse: 91.9965\n",
      "Epoch 45/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1711 - loss: 89.9668 - mae: 5.7870 - mse: 89.9668 - val_accuracy: 0.1779 - val_loss: 91.9461 - val_mae: 5.8755 - val_mse: 91.9461\n",
      "Epoch 46/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1711 - loss: 89.9524 - mae: 5.7862 - mse: 89.9524 - val_accuracy: 0.1932 - val_loss: 91.6934 - val_mae: 5.7786 - val_mse: 91.6934\n",
      "Epoch 47/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1724 - loss: 89.8956 - mae: 5.7857 - mse: 89.8956 - val_accuracy: 0.1579 - val_loss: 91.6290 - val_mae: 5.8711 - val_mse: 91.6290\n",
      "Epoch 48/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1698 - loss: 89.8153 - mae: 5.7851 - mse: 89.8153 - val_accuracy: 0.1915 - val_loss: 91.8192 - val_mae: 5.8199 - val_mse: 91.8192\n",
      "Epoch 49/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1715 - loss: 89.8119 - mae: 5.7851 - mse: 89.8119 - val_accuracy: 0.1480 - val_loss: 91.6262 - val_mae: 5.8844 - val_mse: 91.6262\n",
      "Epoch 50/50\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.1706 - loss: 89.7287 - mae: 5.7814 - mse: 89.7287 - val_accuracy: 0.1393 - val_loss: 93.2887 - val_mae: 5.9689 - val_mse: 93.2887\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeeaee6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 466us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Evaluation:\n",
      "  MAE: 5.9689\n",
      "  RMSE: 9.6586\n",
      "  Accuracy: 0.1652\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).flatten()\n",
    "rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))\n",
    "mae = np.mean(np.abs(y_test - y_pred))\n",
    "acc = np.mean(np.isclose(np.round(y_test), np.round(y_pred)))  # crude regression accuracy\n",
    "\n",
    "print(f\"\\nFinal Model Evaluation:\\n  MAE: {mae:.4f}\\n  RMSE: {rmse:.4f}\\n  Accuracy: {acc:.4f}\")\n",
    "model.save(os.path.join(MODEL_DIR, \"mlp_large_tuned.h5\"))\n",
    "plot_training(history, \"Large MLP (Tuned)\", \"training_large_tuned.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfab703a",
   "metadata": {},
   "source": [
    "Not the best numbers, next few steps - \n",
    "1. Baseline from mean of y_train -> check wif the NN is beating this\n",
    "2. Try different batch size and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a8f394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline (mean predictor):\n",
      "  MAE: 0.7706\n",
      "  RMSE: 1.0066\n",
      "  R²: -0.0001\n"
     ]
    }
   ],
   "source": [
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "y_baseline = np.full_like(y_test_scaled, fill_value=np.mean(y_train_scaled))\n",
    "baseline_mae = mean_absolute_error(y_test_scaled, y_baseline)\n",
    "baseline_rmse = np.sqrt(mean_squared_error(y_test_scaled, y_baseline))\n",
    "baseline_r2 = r2_score(y_test_scaled, y_baseline)\n",
    "\n",
    "print(f\"\\nBaseline (mean predictor):\\n\"\n",
    "      f\"  MAE: {baseline_mae:.4f}\\n\"\n",
    "      f\"  RMSE: {baseline_rmse:.4f}\\n\"\n",
    "      f\"  R²: {baseline_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edf5d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03e3b584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.8933 - mae: 0.7242 - mse: 0.8933 - val_accuracy: 0.0000e+00 - val_loss: 0.8036 - val_mae: 0.6713 - val_mse: 0.8036\n",
      "Epoch 2/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.6995 - mae: 0.5961 - mse: 0.6995 - val_accuracy: 0.0000e+00 - val_loss: 0.6329 - val_mae: 0.5392 - val_mse: 0.6329\n",
      "Epoch 3/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.6030 - mae: 0.5137 - mse: 0.6030 - val_accuracy: 0.0000e+00 - val_loss: 0.5925 - val_mae: 0.5060 - val_mse: 0.5925\n",
      "Epoch 4/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5827 - mae: 0.4941 - mse: 0.5827 - val_accuracy: 0.0000e+00 - val_loss: 0.5817 - val_mae: 0.4916 - val_mse: 0.5817\n",
      "Epoch 5/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5748 - mae: 0.4844 - mse: 0.5748 - val_accuracy: 0.0000e+00 - val_loss: 0.5761 - val_mae: 0.4832 - val_mse: 0.5761\n",
      "Epoch 6/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5701 - mae: 0.4778 - mse: 0.5701 - val_accuracy: 0.0000e+00 - val_loss: 0.5725 - val_mae: 0.4792 - val_mse: 0.5725\n",
      "Epoch 7/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5670 - mae: 0.4733 - mse: 0.5670 - val_accuracy: 0.0000e+00 - val_loss: 0.5702 - val_mae: 0.4771 - val_mse: 0.5702\n",
      "Epoch 8/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5647 - mae: 0.4705 - mse: 0.5647 - val_accuracy: 0.0000e+00 - val_loss: 0.5684 - val_mae: 0.4743 - val_mse: 0.5684\n",
      "Epoch 9/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5630 - mae: 0.4682 - mse: 0.5630 - val_accuracy: 0.0000e+00 - val_loss: 0.5671 - val_mae: 0.4716 - val_mse: 0.5671\n",
      "Epoch 10/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5617 - mae: 0.4665 - mse: 0.5617 - val_accuracy: 0.0000e+00 - val_loss: 0.5661 - val_mae: 0.4680 - val_mse: 0.5661\n",
      "Epoch 11/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5606 - mae: 0.4652 - mse: 0.5606 - val_accuracy: 0.0000e+00 - val_loss: 0.5653 - val_mae: 0.4656 - val_mse: 0.5653\n",
      "Epoch 12/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5597 - mae: 0.4638 - mse: 0.5597 - val_accuracy: 0.0000e+00 - val_loss: 0.5643 - val_mae: 0.4695 - val_mse: 0.5643\n",
      "Epoch 13/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5589 - mae: 0.4631 - mse: 0.5589 - val_accuracy: 0.0000e+00 - val_loss: 0.5635 - val_mae: 0.4669 - val_mse: 0.5635\n",
      "Epoch 14/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5582 - mae: 0.4624 - mse: 0.5582 - val_accuracy: 0.0000e+00 - val_loss: 0.5630 - val_mae: 0.4662 - val_mse: 0.5630\n",
      "Epoch 15/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5576 - mae: 0.4615 - mse: 0.5576 - val_accuracy: 0.0000e+00 - val_loss: 0.5625 - val_mae: 0.4642 - val_mse: 0.5625\n",
      "Epoch 16/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5571 - mae: 0.4609 - mse: 0.5571 - val_accuracy: 0.0000e+00 - val_loss: 0.5621 - val_mae: 0.4658 - val_mse: 0.5621\n",
      "Epoch 17/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5566 - mae: 0.4605 - mse: 0.5566 - val_accuracy: 0.0000e+00 - val_loss: 0.5616 - val_mae: 0.4626 - val_mse: 0.5616\n",
      "Epoch 18/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5562 - mae: 0.4599 - mse: 0.5562 - val_accuracy: 0.0000e+00 - val_loss: 0.5613 - val_mae: 0.4641 - val_mse: 0.5613\n",
      "Epoch 19/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5558 - mae: 0.4594 - mse: 0.5558 - val_accuracy: 0.0000e+00 - val_loss: 0.5608 - val_mae: 0.4633 - val_mse: 0.5608\n",
      "Epoch 20/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5554 - mae: 0.4592 - mse: 0.5554 - val_accuracy: 0.0000e+00 - val_loss: 0.5606 - val_mae: 0.4630 - val_mse: 0.5606\n",
      "Epoch 21/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5551 - mae: 0.4590 - mse: 0.5551 - val_accuracy: 0.0000e+00 - val_loss: 0.5607 - val_mae: 0.4592 - val_mse: 0.5607\n",
      "Epoch 22/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5547 - mae: 0.4584 - mse: 0.5547 - val_accuracy: 0.0000e+00 - val_loss: 0.5599 - val_mae: 0.4617 - val_mse: 0.5599\n",
      "Epoch 23/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5545 - mae: 0.4582 - mse: 0.5545 - val_accuracy: 0.0000e+00 - val_loss: 0.5599 - val_mae: 0.4619 - val_mse: 0.5599\n",
      "Epoch 24/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5542 - mae: 0.4580 - mse: 0.5542 - val_accuracy: 0.0000e+00 - val_loss: 0.5594 - val_mae: 0.4614 - val_mse: 0.5594\n",
      "Epoch 25/25\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.5539 - mae: 0.4577 - mse: 0.5539 - val_accuracy: 0.0000e+00 - val_loss: 0.5594 - val_mae: 0.4613 - val_mse: 0.5594\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    validation_data=(X_test_scaled, y_test_scaled),\n",
    "    epochs=25,\n",
    "    batch_size=128,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87addde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435us/step\n",
      "\n",
      "Final Model Evaluation (scaled):\n",
      "  MAE: 0.4613\n",
      "  RMSE: 0.7479\n",
      "  R²: 0.4479\n"
     ]
    }
   ],
   "source": [
    "y_pred_scaled = model.predict(X_test_scaled).flatten()\n",
    "mae = mean_absolute_error(y_test_scaled, y_pred_scaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))\n",
    "r2 = r2_score(y_test_scaled, y_pred_scaled)\n",
    "\n",
    "print(f\"\\nFinal Model Evaluation (scaled):\\n\"\n",
    "      f\"  MAE: {mae:.4f}\\n\"\n",
    "      f\"  RMSE: {rmse:.4f}\\n\"\n",
    "      f\"  R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c7fc00",
   "metadata": {},
   "source": [
    "- Model seems to be learning from data, with drops in RMSE and MAE\n",
    "- Still improvements to be made\n",
    "- Explore feature engineering, more complex models regularization, CV?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd3cc30",
   "metadata": {},
   "source": [
    "## Further Improvements: Feature Engineering & Advanced Tuning\n",
    "We'll now try to improve the large MLP by adding feature engineering and using more advanced hyperparameter search methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b28edc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineered shapes: X_train_fe (360000, 135), X_test_fe (90000, 135)\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering: Add polynomial and interaction features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "X_train_fe = poly.fit_transform(X_train)\n",
    "X_test_fe = poly.transform(X_test)\n",
    "\n",
    "print(f\"Feature engineered shapes: X_train_fe {X_train_fe.shape}, X_test_fe {X_test_fe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6164bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 24s]\n",
      "val_mae: 5.8582682609558105\n",
      "\n",
      "Best val_mae So Far: 5.798402309417725\n",
      "Total elapsed time: 00h 12m 17s\n",
      "\n",
      "Search: Running Trial #6\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "4                 |4                 |num_layers\n",
      "384               |352               |units_0\n",
      "relu              |tanh              |activation_0\n",
      "192               |448               |units_1\n",
      "tanh              |tanh              |activation_1\n",
      "adam              |adam              |optimizer\n",
      "0.0016335         |0.00026556        |lr\n",
      "480               |32                |units_2\n",
      "relu              |relu              |activation_2\n",
      "384               |32                |units_3\n",
      "relu              |relu              |activation_3\n",
      "288               |None              |units_4\n",
      "relu              |None              |activation_4\n",
      "\n",
      "Epoch 1/40\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 95.5278 - mae: 5.9638 - mse: 95.5278 - val_loss: 93.3207 - val_mae: 5.9749 - val_mse: 93.3207\n",
      "Epoch 2/40\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 93.3605 - mae: 5.8799 - mse: 93.3605 - val_loss: 93.7537 - val_mae: 5.7810 - val_mse: 93.7537\n",
      "Epoch 3/40\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 93.0021 - mae: 5.8713 - mse: 93.0021 - val_loss: 93.3895 - val_mae: 6.1960 - val_mse: 93.3895\n",
      "Epoch 4/40\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 92.5512 - mae: 5.8601 - mse: 92.5512 - val_loss: 92.6922 - val_mae: 5.9721 - val_mse: 92.6922\n",
      "Epoch 5/40\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 92.7760 - mae: 5.8727 - mse: 92.7760 - val_loss: 93.3152 - val_mae: 6.0074 - val_mse: 93.3152\n",
      "Epoch 6/40\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 92.5708 - mae: 5.8779 - mse: 92.5708 - val_loss: 93.2148 - val_mae: 6.0513 - val_mse: 93.2148\n",
      "Epoch 7/40\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 92.8562 - mae: 5.8821 - mse: 92.8562 - val_loss: 94.9454 - val_mae: 6.0603 - val_mse: 94.9454\n",
      "Epoch 8/40\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 92.7233 - mae: 5.8658 - mse: 92.7233 - val_loss: 93.6415 - val_mae: 5.9674 - val_mse: 93.6415\n",
      "Epoch 9/40\n",
      "\u001b[1m3283/5625\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 92.0875 - mae: 5.8777 - mse: 92.0875"
     ]
    }
   ],
   "source": [
    "# Advanced Hyperparameter Tuning: Bayesian Optimization\n",
    "from keras_tuner.tuners import BayesianOptimization\n",
    "\n",
    "def build_advanced_mlp(hp):\n",
    "    model = keras.Sequential()\n",
    "    input_dim = X_train_fe.shape[1]\n",
    "    model.add(layers.Input(shape=(input_dim,)))\n",
    "    num_layers = hp.Int(\"num_layers\", 2, 6)\n",
    "    for i in range(num_layers):\n",
    "        units = hp.Int(f\"units_{i}\", 32, 512, step=32)\n",
    "        activation = hp.Choice(f\"activation_{i}\", [\"relu\", \"tanh\"])\n",
    "        model.add(layers.Dense(units=units, activation=activation))\n",
    "    model.add(layers.Dense(1, activation=\"linear\"))\n",
    "    optimizer_choice = hp.Choice(\"optimizer\", [\"adam\", \"sgd\", \"rmsprop\"])\n",
    "    learning_rate = hp.Float(\"lr\", 1e-4, 1e-2, sampling=\"log\")\n",
    "    if optimizer_choice == \"adam\":\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == \"sgd\":\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\", \"mse\"])\n",
    "    return model\n",
    "\n",
    "bayes_tuner = BayesianOptimization(\n",
    "    build_advanced_mlp,\n",
    "    objective=\"val_mae\",\n",
    "    max_trials=20,\n",
    "    directory=\"tuner_logs\",\n",
    "    project_name=\"large_mlp_bayes_tuning\"\n",
    ")\n",
    "\n",
    "stop_early = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7)\n",
    "bayes_tuner.search(\n",
    "    X_train_fe, y_train,\n",
    "    validation_data=(X_test_fe, y_test),\n",
    "    callbacks=[stop_early],\n",
    "    batch_size=64,\n",
    "    epochs=40\n",
    ")\n",
    "best_bayes_hps = bayes_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "for hp in best_bayes_hps.values.keys():\n",
    "    print(f\"  - {hp}: {best_bayes_hps.get(hp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c883fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate improved model\n",
    "advanced_model = bayes_tuner.hypermodel.build(best_bayes_hps)\n",
    "history_adv = advanced_model.fit(\n",
    "    X_train_fe, y_train,\n",
    "    validation_data=(X_test_fe, y_test),\n",
    "    epochs=40,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_adv = advanced_model.predict(X_test_fe).flatten()\n",
    "mae_adv = mean_absolute_error(y_test, y_pred_adv)\n",
    "rmse_adv = np.sqrt(mean_squared_error(y_test, y_pred_adv))\n",
    "r2_adv = r2_score(y_test, y_pred_adv)\n",
    "\n",
    "print(f\"\\nImproved Model Evaluation:\\n  MAE: {mae_adv:.4f}\\n  RMSE: {rmse_adv:.4f}\\n  R²: {r2_adv:.4f}\")\n",
    "advanced_model.save(os.path.join(MODEL_DIR, \"mlp_large_advanced_tuned.h5\"))\n",
    "plot_training(history_adv, \"Large MLP (Advanced)\", \"training_large_advanced_tuned.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e440d5",
   "metadata": {},
   "source": [
    "## Advanced Model Improvements\n",
    "Let's try more advanced deep learning techniques: residual connections, dropout, batch normalization, and learning rate scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156d30dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual MLP with Dropout and BatchNorm\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def build_residual_mlp(input_dim, n_layers=4, units=128, dropout_rate=0.2, l2_reg=1e-4):\n",
    "    inputs = keras.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(units, activation='relu', kernel_regularizer=regularizers.l2(l2_reg))(inputs)\n",
    "    for i in range(n_layers):\n",
    "        shortcut = x\n",
    "        x = layers.Dense(units, activation='relu', kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        x = layers.Add()([x, shortcut])  # Residual connection\n",
    "    outputs = layers.Dense(1, activation='linear')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=['mae', 'mse'])\n",
    "    return model\n",
    "\n",
    "res_mlp = build_residual_mlp(X_train_fe.shape[1], n_layers=3, units=256, dropout_rate=0.3, l2_reg=1e-3)\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
    "\n",
    "history_res = res_mlp.fit(\n",
    "    X_train_fe, y_train,\n",
    "    validation_data=(X_test_fe, y_test),\n",
    "    epochs=40,\n",
    "    batch_size=64,\n",
    "    callbacks=[lr_scheduler],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "res_pred = res_mlp.predict(X_test_fe).flatten()\n",
    "mae_res = mean_absolute_error(y_test, res_pred)\n",
    "rmse_res = np.sqrt(mean_squared_error(y_test, res_pred))\n",
    "r2_res = r2_score(y_test, res_pred)\n",
    "\n",
    "print(f\"\\nResidual MLP Evaluation:\\n  MAE: {mae_res:.4f}\\n  RMSE: {rmse_res:.4f}\\n  R²: {r2_res:.4f}\")\n",
    "res_mlp.save(os.path.join(MODEL_DIR, \"mlp_large_residual_tuned.h5\"))\n",
    "plot_training(history_res, \"Residual MLP\", \"training_residual_mlp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86780e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble: Average predictions from best models\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Predict with advanced and residual models\n",
    "ensemble_preds = (y_pred_adv + res_pred) / 2\n",
    "mae_ensemble = mean_absolute_error(y_test, ensemble_preds)\n",
    "rmse_ensemble = np.sqrt(mean_squared_error(y_test, ensemble_preds))\n",
    "r2_ensemble = r2_score(y_test, ensemble_preds)\n",
    "\n",
    "print(f\"\\nEnsemble Model Evaluation:\\n  MAE: {mae_ensemble:.4f}\\n  RMSE: {rmse_ensemble:.4f}\\n  R²: {r2_ensemble:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde9276b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (neural-pricer venv)",
   "language": "python",
   "name": "neural-pricer-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
